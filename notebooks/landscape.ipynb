{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# History\n",
    "- 1936: Universal Turing Machine - Computing Machinery and Intelligence - explored AI!\n",
    "- 1946: John von Neumann Universal Computing Machine\n",
    "- 1943: Warren McCulloch & Walter Pitts: cogsci rep of neuron; Frank Rosemblatt uses to create Perceptron (-> neural networks by way of MLP)\n",
    "- 1950s-70s: \"AI\" coined @Dartmouth workshop 1956 - [goal to simulate all aspects of intelligence](http://jmc.stanford.edu/articles/dartmouth/dartmouth.pdf). John McCarthy, Marvin Minksy, Arthur Samuel, Oliver Selfridge, Ray Solomonoff, Allen Newell, Herbert Simon Newell & Simon: Hueristics -> Logic Theories, General Problem Solver\n",
    "  - Slefridge: Computer Vision\n",
    "  - NLP\n",
    "  - Artificial Intelligence Center at SRI International (then Stanford Research Institute) conducted research on a mobile [robot system nicknamed “Shakey.”](http://www.ai.sri.com/shakey/)\n",
    "  - Feigenbaum: Expert systems\n",
    "  - GOFAI / symbolism: operations research / management science; logic-based; knowledge-based / expert systems\n",
    "- 1970s: Lighthill report (James Lighthill) -> [AI Winter paper](http://www.chilton-computing.org.uk/inf/literature/reports/lighthill_report/p001.htm)\n",
    "- 1990s: Yann LeCunn [Object Recognition with Gradient-Based Learning paper](http://yann.lecun.com/exdb/publis/pdf/lecun-99.pdf)\n",
    "- 2006: Geoffrey Hinton et al. publish paper showing how to train a [deep neural network capable of recognizing handwritten digits with >98% confidence paper](https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf)\n",
    "- 2015 Bloomberg, 2015 was whopper for AI in industry\n",
    "  - AlphaGo & DeepMind"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Definition\n",
    "\n",
    "- \"...the science (and art) of programming computers so they can learn from data\" ~ O'Reilly HOML 2nd Ed.\n",
    "- \"...the field of study that gives computers the ability to learn without being explicity programmed\" ~ Arthur Samuel, 1959"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning is great for:\n",
    "1. Problems where existing solutions require a lot of fine-tuning or long  lists of rules.\n",
    "1. Complex problems which traditional approaches yield no good solution\n",
    "1. Fluctuating environments that requires adapting to new data\n",
    "1. Getting insights on complex problems and large amounts of data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Types of Machine Learning:\n",
    "\n",
    "1. Supervised (labelled data)\n",
    "    1. k-Nearest Neighbors\n",
    "    1. Linear Regression\n",
    "    1. Logistic Regression\n",
    "    1. Support Vector Machines (SVM)\n",
    "    1. Decision Trees\n",
    "    1. Random Forests\n",
    "    1. Neural Networks\n",
    "1. Semi-supervised\n",
    "1. Unsupervised (unlabelled data)\n",
    "    1. Clustering\n",
    "        1. K-Means\n",
    "        1. DBSCAN\n",
    "        1. Hierarchical Cluster Analysis (HCA)\n",
    "    1. Anomaly Detection and Novelty Detection\n",
    "        1. One-class SVM\n",
    "        1. Isolation Forest\n",
    "    1. Visualization and Dimensionality Reduction\n",
    "        1. Principal Component Analysis (PCA)\n",
    "        1. Kernel PCA\n",
    "        1. Locally Linear Embedding (LLE)\n",
    "        1. t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "    1. Association Rule Learning\n",
    "        1. Apriori\n",
    "        1. Eclat\n",
    "1. Reinforcement Learning (Agent)\n",
    "\n",
    "## Types of Learning\n",
    "\n",
    "1. Batch Learning\n",
    "    1. Offline learning. Must learn using all the data. Updates requireL training new version on full dataset, stopping old, serving new model.\n",
    "1. Online Learning\n",
    "    1. Incremental learning. Learns from feeds or mini-batches of data.\n",
    "1. Model-based Learning\n",
    "    1. Generalize based on examples."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Examples of Apps\n",
    "\n",
    "## Image Classification\n",
    "1. Analyze images of products on a production line to automatically classify them. Convolutional Neural Network.\n",
    "1. Detecting tumors in brain scans. Semantic Segmentation classifying each pixel in the scan. Convolutional Neural Network.\n",
    "\n",
    "## Natural Language Processing (NLP)\n",
    "1. Automatically classifying new articles. Text classification. Recurrent Neural Network, CNN or Transformers.\n",
    "1. Automatically flagging offensive comments.\n",
    "1. Summarizing long documents automatically.\n",
    "1. Creating a chatbot or personal assistant. Natural Language Understanding (NLU) and question-answer modules.\n",
    "\n",
    "## Speech Recognition\n",
    "1. Make app respond to voice commands.\n",
    "\n",
    "## Regression\n",
    "1. Forecasting company revenue next year based on performance metrics.\n",
    "1. Predicting home prices based on home attributes and pictures.\n",
    "\n",
    "## Anomaly Detection\n",
    "1. Detecting credit card fraud.\n",
    "\n",
    "## Clustering\n",
    "1. Segmenting customers based on purchases to design different marketing strategies.\n",
    "\n",
    "## Data Visualization\n",
    "1. Represent complex, high dimensional dataset in clear visualizations\n",
    "\n",
    "## Recommender systems\n",
    "1. Recommending products that a client may be interested in based on purchase history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Challenges\n",
    "\n",
    "1. Insufficient quantity of training data (life starts at a billion)\n",
    "1. Poor quality data (unsanitized errors, outliers and noise)\n",
    "1. Irrelevant features (garbage in, garbage out)\n",
    "1. Overfitting training data (learned the training data)\n",
    "1. Underfitting training data (too simple)\n",
    "1. Data mismatch (satellite vs. angle)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}